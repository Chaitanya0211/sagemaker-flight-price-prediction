# âœˆï¸ Flight Price Prediction Using AWS SageMaker

This project develops a machine learning model to predict flight prices based on various features such as airline, source, destination, departure time, arrival time, and more. The model is trained and deployed using AWS SageMaker, and a web application is built with Streamlit to provide an interactive interface for users.

## ğŸ“Œ Project Overview

The objective of this project is to build a regression model that accurately predicts flight prices. By analyzing various factors that influence flight prices, the model can assist travelers, travel agencies, and airlines in making informed decisions.

## ğŸ“‚ Dataset

The dataset used for this project contains information on flights, including:

- ğŸ›« Airline
- ğŸŒ Source
- ğŸŒ Destination
- â° Departure Time
- âŒ› Arrival Time
- ğŸ•’ Duration
- ğŸ”„ Total Stops
- ğŸ“œ Additional Information

## ğŸ› ï¸ Data Preprocessing

Data preprocessing steps include:

1. **ğŸ§¹ Handling Missing Values**: Removing or imputing missing data.
2. **âœ‚ï¸ Removing Whitespace**: Stripping unnecessary whitespace from strings.
3. **ğŸ”¤ Standardizing Text**: Converting text to lowercase and standardizing formats.
4. **ğŸ“… Converting Dates and Times**: Parsing dates and times into appropriate formats.
5. **ğŸ”¢ Encoding Categorical Variables**: Transforming categorical variables into numerical representations.
6. **ğŸ“ Normalizing Numerical Features**: Scaling numerical features for better model performance.

Pandas method chaining is employed throughout the preprocessing pipeline to ensure code readability and maintainability.

## ğŸ” Feature Engineering

Feature engineering involves creating new features that better represent the underlying patterns in the data. In this project, features such as the duration in minutes, departure hour, and arrival hour are extracted and used to enhance model performance. The `feature-engine` library is used for feature transformations, including:

- ğŸ§© Handling missing data with imputation transformers.
- ğŸ“Š Encoding categorical variables using one-hot encoding.
- ğŸ“ Scaling numerical features.

## ğŸ“Š Model Training

The model is trained using AWS SageMaker and the XGBoost algorithm, leveraging SageMakerâ€™s scalable infrastructure. The training process includes:

- **ğŸ“¥ Using S3 Buckets**: Storing and retrieving datasets securely and efficiently.
- **ğŸ’¾ Saving the Best Model**: After training, the best-performing model is saved to an S3 bucket for future use.
- **ğŸ¤– Selecting Algorithms**: Using XGBoost for regression tasks.
- **âš™ï¸ Hyperparameter Tuning**: Optimizing model parameters such as learning rate, max depth, and number of estimators.
- **ğŸ”„ Cross-Validation**: Validating the model to prevent overfitting.

## ğŸš€ Model Deployment

After training, the model is deployed using AWS SageMaker's deployment services, allowing it to be accessed for real-time predictions.

## ğŸŒ Web Application

A web application is built using Streamlit to provide an interactive interface where users can input flight details and receive price predictions. The app is deployed on Streamlit Cloud for accessibility.

## âš™ï¸ Getting Started

To get a local copy up and running, follow these steps:

### Prerequisites

- ğŸ Python 3.6 or higher
- ğŸ–¥ï¸ AWS Account with SageMaker access
- ğŸŒ Streamlit Account for deployment

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/Chaitanya0211/sagemaker-flight-price-prediction.git
   ```

2. Navigate to the project directory:

   ```bash
   cd sagemaker-flight-price-prediction
   ```

3. Install the required packages:

   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“¦ Dependencies

The project requires the following Python packages:

- ğŸ¼ pandas
- ğŸ”¢ numpy
- ğŸ§  scikit-learn
- ğŸ“ˆ xgboost
- ğŸ–¥ï¸ streamlit
- â˜ï¸ boto3
- ğŸ”§ feature-engine

These can be installed using the `requirements.txt` file provided in the repository.

## â–¶ï¸ Usage

1. **ğŸ“‚ Data Preparation**: Ensure the dataset is available in the `Data` directory.
2. **ğŸ“Š Model Training**: Use the Jupyter notebooks in the `Code_Files` directory to preprocess data, engineer features, and train the model using AWS SageMaker and S3 buckets for data storage.
3. **ğŸ’¾ Save Best Model**: After training, save the best-performing model to an S3 bucket.
4. **ğŸš€ Model Deployment**: Deploy the trained model using AWS SageMaker's deployment services.
5. **ğŸŒ Web Application**: Run the Streamlit app locally:

   ```bash
   streamlit run app.py
   ```

   Or deploy it on Streamlit Cloud for public access.


